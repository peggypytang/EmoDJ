{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EmoDJ Music Emotion Recognition Model\n",
    "\n",
    "Training, hyperparameter tuning, and testing of EmoDJ Music Emotion Recognition Model is performed. SVR with RBF kernal is used.\n",
    "\n",
    "Two models are built, one for predicting valence value, one for arousal value. The trained models are saved for the use in EmoDJ Music Player to recognise music emotion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "Emotion in Music Database (1000 songs) is used. Downloaded from http://cvml.unige.ch/databases/emoMusic/\n",
    "\n",
    "Reference:<br>\n",
    "1000 Songs for Emotional Analysis of Music. Proceedings of the ACM multimedia 2013 workshop on Crowdsourcing for Multimedia\n",
    "https://ibug.doc.ic.ac.uk/media/uploads/documents/cmm13-soleymani.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "MODEL_FOLDER = 'model/'\n",
    "DATASET_ANNOT_FOLDER = 'dataset/annotations/'\n",
    "DATASET_FEATURE_FOLDER = 'dataset/default_features/'\n",
    "DATASET_CLIPS_FOLDER = 'dataset/clips_45seconds/'\n",
    "ID_FIELD = 'song_id'\n",
    "\n",
    "def load_dataset():\n",
    "    song_list = pd.read_csv(MODEL_FOLDER + DATASET_ANNOT_FOLDER + 'arousal_cont_average.csv', header=0)[ID_FIELD].astype(str).values\n",
    "    song_list = [s + '.mp3' for s in list(song_list)]\n",
    "    arousal_df = pd.read_csv(MODEL_FOLDER + DATASET_ANNOT_FOLDER + 'arousal_cont_average.csv', header=0).drop(ID_FIELD,axis=1)\n",
    "    arousal_df = arousal_df.astype(np.float16)\n",
    "    valence_df = pd.read_csv(MODEL_FOLDER + DATASET_ANNOT_FOLDER + 'valence_cont_average.csv', header=0).drop(ID_FIELD,axis=1)\n",
    "    valence_df = valence_df.astype(np.float16)\n",
    "\n",
    "    return song_list,arousal_df, valence_df\n",
    "\n",
    "train_song_list,arousal_df, valence_df = load_dataset()\n",
    "arousal_vector = arousal_df.values.flatten()\n",
    "valence_vector = valence_df.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process Features\n",
    "Extract MFCCs for music clips as training data\n",
    "\n",
    "Reference:<br>\n",
    "Feature Selection for Content-Based, Time-Varying Musical Emotion Regression http://music.ece.drexel.edu/files/Navigation/Publications/schmidt2010.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import sklearn\n",
    "\n",
    "def preprocess_feature(folder_path, song_list, istrain):\n",
    "    n_mfcc = 12\n",
    "    mfcc_all = []\n",
    "    #MFCC per time period (500ms)\n",
    "    for file_name in song_list:\n",
    "        count=0\n",
    "        x, sr = librosa.load(folder_path + file_name)\n",
    "        start = int(sr*15) if istrain else 0\n",
    "        for i in range(start, len(x), int(sr*500/1000)):\n",
    "            x_cont = x[i:i+int(sr*500/1000)]\n",
    "            mfccs = librosa.feature.mfcc(x_cont,sr=sr,n_mfcc=n_mfcc)\n",
    "            #for training data, as to align with dataset\n",
    "            #append feature value for music interval shorter than 500ms\n",
    "            mfccs = np.hstack((mfccs, np.zeros((12,22 - mfccs.shape[1]))))\n",
    "            mfccs = mfccs.flatten()\n",
    "            mfcc_all.append(mfccs)\n",
    "            count += 1\n",
    "        #for training data, as to align with dataset\n",
    "        #append feature value for music shorter than 45000ms\n",
    "        if istrain:\n",
    "            if count < 61:\n",
    "                for i in range(61-count):\n",
    "                    mfcc_all.append(mfccs)\n",
    "\n",
    "    return np.vstack(mfcc_all)\n",
    "\n",
    "feature_matrix = preprocess_feature(MODEL_FOLDER + DATASET_CLIPS_FOLDER, train_song_list, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45384, 264)\n"
     ]
    }
   ],
   "source": [
    "print(feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "SVR with RBF kernel is used.\n",
    "\n",
    "Reference:<br>\n",
    "Automated Music Emotion Recognition: A Systematic Evaluation \n",
    "https://pdfs.semanticscholar.org/1a43/325def098ee57ff6f1c0b19a30811fe92304.pdf <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found for arousal SVR:\n",
      "{'C': 1}\n",
      "Score: 0.6597154521291105\n",
      "Best parameters set found for valence SVR:\n",
      "{'C': 1}\n",
      "Score: 0.4534642313757411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "grid_parameters = [{'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "feature_matrix_mean = feature_matrix.mean(axis=0)\n",
    "feature_matrix_std = feature_matrix.std(axis=0)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "feature_matrix_scaled = scaler.fit_transform(feature_matrix)\n",
    "\n",
    "X_aro_train, X_aro_test, y_aro_train, y_aro_test = train_test_split(feature_matrix_scaled, arousal_vector, test_size=0.25,\n",
    "                                              random_state=5)\n",
    "\n",
    "X_val_train, X_val_test, y_val_train, y_val_test = train_test_split(feature_matrix_scaled, valence_vector, test_size=0.25,\n",
    "                                              random_state=5)\n",
    "\n",
    "svr_arousal=SVR(kernel='rbf',gamma='auto')\n",
    "svr_arousal_cv=GridSearchCV(svr_arousal,grid_parameters,cv=5,return_train_score=True)\n",
    "svr_arousal_cv.fit(X_aro_train, y_aro_train)\n",
    "print(\"Best parameters set found for arousal SVR:\")\n",
    "print(svr_arousal_cv.best_params_)\n",
    "print(\"Score:\", svr_arousal_cv.best_score_)\n",
    "\n",
    "svr_valence=SVR(kernel='rbf',gamma='auto')\n",
    "svr_valence_cv=GridSearchCV(svr_valence,grid_parameters,cv=5,return_train_score=True)\n",
    "svr_valence_cv.fit(X_val_train, y_val_train)\n",
    "print(\"Best parameters set found for valence SVR:\")\n",
    "print(svr_valence_cv.best_params_)\n",
    "print(\"Score:\", svr_valence_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute 3-fold cross validation on average distance and mean absolute errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pred_aro_cv = []\n",
    "pred_val_cv = []\n",
    "average_distance_cv = []\n",
    "mae_aro_cv = []\n",
    "mae_val_cv = []\n",
    "\n",
    "feature_matrix_mean = feature_matrix.mean(axis=0)\n",
    "feature_matrix_std = feature_matrix.std(axis=0)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "feature_matrix_scaled = scaler.fit_transform(feature_matrix)\n",
    "\n",
    "for i in range(3):\n",
    "    y_for_split = []\n",
    "    for x,y in zip(arousal_vector,valence_vector):\n",
    "        y_for_split.append((x,y))\n",
    "    y_for_split = np.vstack(y_for_split)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_matrix_scaled, y_for_split, test_size=0.05)\n",
    "\n",
    "    y_aro_train, y_val_train = np.hsplit(y_train, 2)\n",
    "    y_aro_test, y_val_test = np.hsplit(y_test, 2)\n",
    "    \n",
    "    y_aro_train = y_aro_train.flatten()\n",
    "    y_val_train = y_val_train.flatten()\n",
    "    y_aro_test = y_aro_test.flatten()\n",
    "    y_val_test = y_val_test.flatten()\n",
    "    \n",
    "    svr_arousal_score=SVR(kernel='rbf',gamma='auto',C=1.0)\n",
    "    svr_valence_score=SVR(kernel='rbf',gamma='auto',C=1.0)\n",
    "    svr_arousal_score.fit(X_train,y_aro_train)\n",
    "    svr_valence_score.fit(X_train,y_val_train)\n",
    "    pred_aro_test = svr_arousal_score.predict(X_test)\n",
    "    pred_val_test = svr_valence_score.predict(X_test)\n",
    "    \n",
    "    mae_aro = mean_absolute_error(y_aro_test,pred_aro_test)\n",
    "    mae_val = mean_absolute_error(y_val_test,pred_val_test)\n",
    "    average_distance = np.sqrt((pred_aro_test-y_aro_test)**2+(pred_val_test-y_val_test)**2).mean()\n",
    "    \n",
    "    pred_aro_cv.append(pred_aro_test)\n",
    "    pred_val_cv.append(pred_val_test)\n",
    "    mae_aro_cv.append(mae_aro)\n",
    "    mae_val_cv.append(mae_val)\n",
    "    average_distance_cv.append(average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance on 3-fold cross validation: 0.20419702700876996\n",
      "Mean absolute error of valence value on 3-fold cross validation: 0.13571890856879773\n",
      "Mean absolute error of arousal value on 3-fold cross validation: 0.12937129979933767\n"
     ]
    }
   ],
   "source": [
    "print('Average distance on 3-fold cross validation:', sum(average_distance_cv)/len(average_distance_cv))\n",
    "print('Mean absolute error of valence value on 3-fold cross validation:', sum(mae_val_cv)/len(mae_val_cv))\n",
    "print('Mean absolute error of arousal value on 3-fold cross validation:', sum(mae_aro_cv)/len(mae_aro_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-sided T Test against mean absolute error of baseline\n",
    "Reference: <br>\n",
    "Automated Music Emotion Recognition: A Systematic Evaluation <br>\n",
    "Table 7. MAE and R2 achieved by the best regressors (SVR-RBF with parameter search and using all standardized features)<br>\n",
    "https://pdfs.semanticscholar.org/1a43/325def098ee57ff6f1c0b19a30811fe92304.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value for H1 MAE of proposed valence regressor < Baseline:\n",
      "0.00023089405986836825\n",
      "P-value for H1 MAE of proposed arousal regressor < Baseline:\n",
      "0.0010279466571317222\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "print(\"P-value for H1 MAE of proposed valence regressor < Baseline:\")\n",
    "print(stats.ttest_1samp(mae_val_cv,0.198).pvalue*0.5)\n",
    "\n",
    "print(\"P-value for H1 MAE of proposed arousal regressor < Baseline:\")\n",
    "print(stats.ttest_1samp(mae_aro_cv,0.156).pvalue*0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Arousal and Valence SVR with all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arousal_model = SVR(kernel='rbf',gamma='auto',C=1)\n",
    "valence_model = SVR(kernel='rbf',gamma='auto',C=1)\n",
    "\n",
    "arousal_model.fit(feature_matrix_scaled, arousal_vector)\n",
    "valence_model.fit(feature_matrix_scaled, valence_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(MODEL_FOLDER + 'arousal_model.pkl', 'wb') as f:\n",
    "    pickle.dump(arousal_model,f)\n",
    "with open(MODEL_FOLDER + 'valence_model.pkl', 'wb') as f:\n",
    "    pickle.dump(valence_model,f)\n",
    "with open(MODEL_FOLDER + 'feature_matrix_mean.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_matrix_mean,f)\n",
    "with open(MODEL_FOLDER + 'feature_matrix_std.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_matrix_std,f)\n",
    "with open(MODEL_FOLDER + 'feature_matrix_scaled.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_matrix_scaled,f)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
